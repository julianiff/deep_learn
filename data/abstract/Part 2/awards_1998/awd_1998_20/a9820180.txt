Title       : Designing Robotic Desktop Assistants Using Dynamics-based Shape-Sensing
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : June 27,  2001      
File        : a9820180

Award Number: 9820180
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  1999  
Expires     : August 31,  2003     (Estimated)
Expected
Total Amt.  : $266765             (Estimated)
Investigator: Michael A. Erdmann me@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9139,HPCC,
Abstract    :
              Abstract
 
IIS-9820180
Erdmann, Michael
Carnegie Mellon University 
$63,876
              - 12 mos.

Designing Robotic Desktop Assistants Using Dynamics-Based
              Shape-Sensing

This is the first year funding of a three year continuing
              award. This research seeks to understand shape-aware robotic manipulation in
              order to improve the versatility of robots interacting with their environments.
               As robots become more human-assistive, they will need to manipulate a large
              variety of novel objects of varying shapes and sizes.  Key to recognizing and
              manipulating these objects will be the integration of numerous passive and
              active sensory modalities.  This research focuses on the information content of
              active tactile manipulation strategies.  For instance, when grasping an object
              of known shape and dynamics but unknown pose, the time history of the contact
              points on the fingers often provides enough constraint to reveal the
              orientation of the object.  More difficult is the task of picking up an object
              of unknown shape and unknown dynamics.  Again, the finger configurations
              required to touch the object provide constraints on the possible shapes of the
              object.  As the fingers move and the object slips in the fingers, these
              constraints evolve over time, thereby permitting reconstruction of the shape of
              the object.
The difference between theses tasks lies primarily in the number
              of fingers required to touch the object, the degree of active manipulation, and
              the character of internal models.  In between these extremes of known and
              unknown shape lie more typical tasks, in which
partial shape information
              exists.  For instance, a human or robot may know the rough shape and pose of an
              object from visual inspection; grasping strategies then reveal the fine shape
              and dynamics. The impact of this research lies most directly in manipulation,
              with possible additional impact on haptic displays and industrial automation. 
              The shape-sensing routines produced by this research will make it easier to
              program robots.  Rather than requiring a robot programmer to measure object
              shapes and locations precisely, this
research will provide automatic methods
              for extracting that information during robot manipulation.  Such automatic
              methods will facilitate robotic aids.  Moreover, understanding the nature of
              the shape information produced during manipulation will facilitate the design
              of better haptic devices.

