Title       : CISE Research Instrumentation: Speech Synthesis from Fluid Dynamic Principles,
               with Application to Human-Computer Interaction
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : December 17,  1998  
File        : a9818313

Award Number: 9818313
Award Instr.: Standard Grant                               
Prgm Manager: Frederica Darema                        
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : December 15,  1998  
Expires     : November 30,  2001   (Estimated)
Expected
Total Amt.  : $70000              (Estimated)
Investigator: James L. Flanagan jlf@caip.rutgers.edu  (Principal Investigator current)
              Ivan Marsic  (Co-Principal Investigator current)
              Joseph Wilder  (Co-Principal Investigator current)
              Michael Krane  (Co-Principal Investigator current)
Sponsor     : Rutgers Univ New Brunswick
	      ASB III, 3 Rutgers Plaza
	      New Brunswick, NJ  08901    732/932-0150

NSF Program : 2890      CISE INSTRUMENTATION
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9216,HPCC,
Abstract    :
              9818313
Flanagan, James L.
Krane, Michael
Rutgers University - Busch
              Campus

CISE Research Instrumentation:  Speech Synthesis from Fluid Dynamic
              Principles,
with Application to Human-Computer Interaction

This research
              instrumentation enables research projects in:

- Synergistic Multi-modal
              Communication in Collaborative Multi-user Environments, and
- Speech Synthesis
              Based upon Fluid Dynamics Principles

To support the aforementioned projects,
              this award contributes to the purchase of image acquisition, networking,
              visualization, and speech processing equipment at Rutgers University CAIP
              Center.

Advanced human-machine interfaces employ multiple modalities through
              which a human user can communicate effectively with computers and complex
              information systems. Interactive speech (in the form of automatic recognition
              and synthesis) is a natural modality, which improves the effectiveness of
              human-machine interfaces.  However, advances in speech technology have been
              limited due to incomplete understanding of the physical mechanisms of human
              speech generation.  A particular deficit has been the lack of naturalness in
              speech synthesis.  Equipment to be instrumented under this proposal will
              directly enable research on the synthesis of natural quality speech using a
              more complete description of the fundamental physics of speech generation (NSF
              contract #IRI-98-00999).  The instrumentation will also support research on
              multi-modal workstations with which human users interact using sight, sound,
              and touch (NSF contract #IRI-96-18854).  Additionally, the proposed
              instrumentation will enhance the effectiveness of the speech component in
              multi-modal interfaces through visual tracking.  And, the speech interface will
              directly benefit from a machine voice that exhibits improved human-like
              quality.




