Title       : CISE Research Instrumentation: Data-Driven Modeling for Real-Time Interaction
               and Animation
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : August 30,  2002    
File        : a9818287

Award Number: 9818287
Award Instr.: Standard Grant                               
Prgm Manager: Frederica Darema                        
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : February 15,  1999  
Expires     : October 31,  2000    (Estimated)
Expected
Total Amt.  : $120000             (Estimated)
Investigator: Jessica Hodgins   (Principal Investigator current)
              Irfan Essa  (Co-Principal Investigator current)
              Christopher G. Atkeson  (Co-Principal Investigator current)
Sponsor     : GA Tech Res Corp - GIT
	      Office of Sponsored Programs
	      Atlanta, GA  303320420    404/385-0866

NSF Program : 2890      CISE INSTRUMENTATION
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9216,HPCC,
Abstract    :
              9818287
Hodgins, Jessica K.
Atkeson, Christopher G.
Georgia Institute of
              Technology

CISE Research Instrumentation:  Data-Driven Modeling for
              Real-time Interaction and Animation

This research instrumentation enables
              research projects in:

- Perception of Action
- Learning from
              Demonstration
- Animating with Experimentally Determined Parameters, and
-
              Modeling Facial Expressions

To support the aforementioned projects, for the
              capture, modeling, recognition, and generation of human motion, this award
              contributes to the purchase of motion capture equipment, graphics workstations,
              and digital cameras at College of Computing in Georgia Institute of Technology.
               The equipment will be used for several projects aimed at making it easy to
              create, control, and interact with artificial humans in
              interactive
environments for training and entertainment.  The cameras and
              motion capture equipment will capture full body and facial motion of the users.
               The processing power of the graphics workstations and other
              available
multi-processors will be used to create data-driven models for
              recognition and generation of human actions ranging from full body motions such
              as a tennis swing to subtle facial expressions.  The power of this technology
              will be demonstrated by constructing interactive environments in which the
              cameras and motion capture equipment will be used for on-line recognition of
              user actions and the graphics workstation will be used to animate human figures
              in real-time, based on the models derived off-line.  The prototype applications
              will be environments where interactivity and realism are key, such as training
              environments for physical tasks and animation of highly interactive and
              responsive characters.


