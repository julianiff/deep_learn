Title       : Flexible Automated Software Test Generation Using AI Planning Technology
Type        : Award
NSF Org     : CCR 
Latest
Amendment
Date        : June 3,  1997       
File        : a9619787

Award Number: 9619787
Award Instr.: Standard Grant                               
Prgm Manager: Frank D. Anger                          
	      CCR  DIV OF COMPUTER-COMMUNICATIONS RESEARCH 
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 15,  1997    
Expires     : July 31,  1999       (Estimated)
Expected
Total Amt.  : $150016             (Estimated)
Investigator: Anneliese Andrews aaa@cs.colostate.edu  (Principal Investigator current)
              Adele E. Howe  (Co-Principal Investigator current)
Sponsor     : Colorado State University
	      
	      Fort Collins, CO  805232002    970/491-1101

NSF Program : 2880      SOFTWARE ENGINEERING AND LANGU
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9216,HPCC,
Abstract    :
              9619787  Software testing is a critical part of software development.  A  new
              approach to software testing based on AI Planning is  investigated. The
              similarity of plans to test cases for some  systems (e.g., command language and
              transaction based systems)  makes the representation well suited for test
              generation. The  representation encourages testers to think at a higher level
              when  designing tests. To exploit these potential advantages, an  automated
              test generator is constructed with an AI planning  system at its core. This
              generator allows representation of  testing goals and testing criteria to
              support a variety of  testing tasks. The project's contribution to Software
              Testing is  to extend how testing goals are articulated. Its contribution to 
              AI planning is developing new search strategies for efficient  planning, and
              determining how to generate goals that conform to  tester's intent, and
              evaluating the efficacy of using AI planners  during software testing. Tasks
              include 1) improve planning  efficiency for generating large tests; 2) include
              representation  of test focus and various test criteria to make the approach 
              flexible; 3) represent high level testing goals to reduce tedium  for testers;
              4) evaluate the efficacy of the new approach to  identify strengths and
              weaknesses of using AI Planning for  testing.  ***
