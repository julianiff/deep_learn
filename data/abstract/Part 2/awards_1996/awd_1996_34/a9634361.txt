Title       : CRI: Cortical Representation of Acoustic Spectra
Type        : Award
NSF Org     : IBN 
Latest
Amendment
Date        : August 26,  1996    
File        : a9634361

Award Number: 9634361
Award Instr.: Standard Grant                               
Prgm Manager: Fred Stollnitz                          
	      IBN  DIV OF INTEGRATIVE BIOLOGY AND NEUROSCIE
	      BIO  DIRECT FOR BIOLOGICAL SCIENCES          
Start Date  : September 1,  1996  
Expires     : August 31,  1997     (Estimated)
Expected
Total Amt.  : $99873              (Estimated)
Investigator: John S. Baras baras@isr.umd.edu  (Principal Investigator current)
              Shihab A. Shamma  (Co-Principal Investigator current)
Sponsor     : U of MD College Park
	      3112 Lee Building
	      College Park, MD  207425141    301/405-6269

NSF Program : 5500      NEUROSCIENCE
Fld Applictn: 0000099   Other Applications NEC                  
              61        Life Science Biological                 
Program Ref : 1054,9107,BIOT,
Abstract    :
                IBN:  9634361  PI:  Baras    Timbre is the percept that allows one to
              distinguish between musical   instruments playing the same note, or between 
              different  vowels  spoken   in the same voice pitch.  Only complex sounds
              composed of many tones have   distinct timbres or sound qualities.  The most
              important physical   correlate of this percept is the distribution of energy in
              these tones.   This energy profile resembles intuitively the distribution of
              light in an   image.  The question addressed in this research is how the
              acoustic   profile (or image) is extracted in the auditory system and how is it
                represented in the brain.  Specifically, we seek to clarify  what   features
              of this acoustic image are important in forming the timbre of   the sound, and
              which features are  redundant and can be ignored.The   results obtained from
              such a study can potentially lead to a better   understanding of how speech and
              musical sounds are preceived.  This in   turn has immediate applications in the
              development of effective automatic   speech recognition systems, in speech and
              music synthesis, in robust   communication channels, and in prosthetic devices
              for the deaf.
