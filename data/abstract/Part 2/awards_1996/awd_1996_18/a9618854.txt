Title       : STIMULATE: Synergistic Multimodal Communication in Collaborative Multiuser
               Environments
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : September 26,  2000 
File        : a9618854

Award Number: 9618854
Award Instr.: Continuing grant                             
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : March 1,  1997      
Expires     : February 29,  2000   (Estimated)
Expected
Total Amt.  : $778440             (Estimated)
Investigator: James L. Flanagan jlf@caip.rutgers.edu  (Principal Investigator current)
              Ivan Marsic  (Co-Principal Investigator current)
              Joseph Wilder  (Co-Principal Investigator current)
              Grigore C. Burdea  (Co-Principal Investigator current)
              Casimir A. Kulikowski  (Co-Principal Investigator current)
Sponsor     : Rutgers Univ New Brunswick
	      ASB III, 3 Rutgers Plaza
	      New Brunswick, NJ  08901    732/932-0150

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
              0116000   Human Subjects                          
Program Ref : 9139,HPCC,
Abstract    :
              The sensory modalities of sight, sound and touch are employed  in  combination  
              to  research  a  new  dimension  in   human-machine  communication.   These
              expanded interface capabilities  build  on  technologies established in related
              work, and are implemented  at  multiple  user  stations  in a networked
              Distributed  System  for  Collaborative  Information Processing  and  Learning 
              (DISCIPLE).  The system provides object-oriented groupware running on Internet 
              protocols as well as on an Asynchronous Transfer Mode intracampus  network.  
              Intelligent  agents at each  user  location  fuse  the  multimodal information
              inputs and decide actions to be  taken  in  the  collaborative  environment.  
              Established  technologies  for  region-of-interest sensing, image
              understanding, face recognition  and  visual  gesture  are applied for
              interaction  in  the  sight  domain.    Automatic  speech  and  speaker 
              recognition,   speech  synthesis,  and  distant-talking autodirective
              microphone  arrays  support   the  sound  dimension.   Gesture  detection,  
              position  sensing,  force feedback gloves and multitasking tactile software 
              are  employed for touch communication.  The DISCIPLE  environment  of multiple
              collaborating users provides a comprehensive test bed  for  quantifying human
              interface designs, and for  measuring  the  synergies  that  can  be  won from
              combinations  of  simultaneous  multimodal   communication.   Results  of  this
                research   will  significantly  broaden  the  utility  of  distributed  
              networked  computing for human users.
