Title       : STIMULATE: Exploiting Nonlocal and Syntactic Word Relationships in Language
               Models for Conversational Speech Recognition
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : May 23,  2000       
File        : a9618874

Award Number: 9618874
Award Instr.: Standard Grant                               
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : March 1,  1997      
Expires     : February 29,  2000   (Estimated)
Expected
Total Amt.  : $749994             (Estimated)
Investigator: Frederick Jelinek jelinek@clsp.jhu.edu  (Principal Investigator current)
              Eric D. Brill  (Co-Principal Investigator current)
              David E. Yarowsky  (Co-Principal Investigator current)
              Sanjeev P. Khudanpur  (Co-Principal Investigator current)
Sponsor     : Johns Hopkins University
	      3400 North Charles Street
	      Baltimore, MD  212182695    301/338-8000

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9139,HPCC,
Abstract    :
              Automated  systems  that  can  interact  with  human   users   in  modalities 
              such  as speech and handwriting will greatly  enhance  productivity  and 
              system  usability. These  systems  will  allow  simple access to information
              and services on the internet.  These  capabilities  are  essential to other 
              tasks,  such  as  enabling  access  by  handicapped users or querying an
              on-line  maintenance  manual  while performing intricate repairs.  A
              statistical  model  of language is a crucial component in such systems, which
              convert  between  speech  or  handwriting and  text,  and  in  statistical 
              machine   translation  systems.   Most  current  algorithms   for  language  
              modeling  exhibit  an  acute  myopia,   basing   their  predictions of the next
              word on only a few immediately  preceding  words.  When humans are faced with a
              comparable task they  easily  outperform  these models using the richer
              linguistic  information  available  to  them from more complete context.  
              Researchers  at  CLSP  propose to investigate and develop novel language 
              modeling  techniques  that  exploit  richer  contextual  information.  They 
              propose  to  examine models that use a variety of  techniques  to  capture 
              syntactic  dependencies  through  dynamic,  hierarchical  models  of  topic,
              and to combine the resulting models  with  the  best  current  ones  using the
              maximum entropy  principle.   This  research  will  focus  on improving the
              recognition  accuracy  of  spontaneous  human speech, but beyond that will 
              provide  insight  into  new  information sources and techniques applicable  to 
              all  applications of language modeling.
