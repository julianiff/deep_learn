Title       : Perception of Stereoscopically-Defined Surfaces and Motion
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : March 24,  1999     
File        : a9602080

Award Number: 9602080
Award Instr.: Continuing grant                             
Prgm Manager: Rodney R. Cocking                       
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : December 15,  1996  
Expires     : October 31,  2000    (Estimated)
Expected
Total Amt.  : $329455             (Estimated)
Investigator: Martin Banks marty@john.berkeley.edu  (Principal Investigator current)
Sponsor     : U of Cal Berkeley
	      
	      Berkeley, CA  94720    415/642-6000

NSF Program : 7252      PERCEPTION, ACTION & COGNITION
Fld Applictn: 0116000   Human Subjects                          
Program Ref : 0000,OTHR,
Abstract    :
              9602080  BANKS    We use our eyes to determine the layout of the scene before us
               and to assess the desirability of our path of motion with respect  to
              stationary and moving obstacles in the scene.  The ease with  which we perceive
              3-D layout and carry out visually-guided  navigation belies the underlying
              complexity of these tasks.  The  primary stimulus information for determining
              scene layout is  binocular disparity (the differences in the two eyes' images 
              which creates the sensation of depth seen in, for example, the  Magic Eye
              Stereograms) and motion parallax (differences in the  speeds at which images
              stream across the retina when a person  moves the head).  Binocular disparity
              and motion parallax are  provided in retinal coordinates, but the positions and
               orientations of surfaces must generally be determined in body-  centered
              coordinates in order to guide appropriate actions of the  limbs and torso. 
              Similarly, the information needed to judge the  direction of an object's motion
              (or one's own motion) is  contained in the changing pattern of light falling on
              the  retinas, but motion direction must generally be estimated  relative to the
              body in order to be useful in guiding motor  responses to objects in the scene.
               This research will examine  how comparisons of the two eyes' images are used
              to determine  surface orientation and curvature and to determine the direction 
              of an object's motion.    This research will be important to our understanding
              of human  space perception, but it may well also have practical  consequences. 
              First, biological systems have evolved robust  mechanisms for estimating
              surface orientation, shape, and  position and for estimating object velocity. 
              A better  understanding of how biological systems perform may lead to  better
              algorithms for mobile robotic systems.  Second, the  perception of an object's
              motion relative to the self is crucial  for action, including the control of a
              motor vehicle.  Thus, a  better understanding could lead to improved procedures
              fo r  assessing driving and flying capability.  Third, a better  understanding
              of the retinal and extra-retinal information used  in the perception of 3D
              layout and motion may well aid  construction of virtual reality displays.   
              ***
