Title       : CISE Postdoctoral Program: Scalability of Software Distributed Shared Memory
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : March 11,  1996     
File        : a9626318

Award Number: 9626318
Award Instr.: Standard Grant                               
Prgm Manager: Stephen R. Mahaney                      
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : April 1,  1996      
Expires     : March 31,  1998      (Estimated)
Expected
Total Amt.  : $46200              (Estimated)
Investigator: Willy Zwaenepoel willy@rice.edu  (Principal Investigator current)
Sponsor     : William Marsh Rice Univ
	      6100 Main Street, MS-16
	      Houston, TX  772511892    713/348-4820

NSF Program : 2885      CISE RESEARCH INFRASTRUCTURE
Fld Applictn: 0000099   Other Applications NEC                  
              31        Computer Science & Engineering          
Program Ref : 9192,9218,HPCC,
Abstract    :
              9626318  Zwaenepoel, Willy  William Marsh Rice University    CISE Postdoctoral
              Program:  Scalability of Software Distributed Shared Memory    This award
              supports CES associate Povl Koch.  Software Distributed Shared Memory (DSM)
              architectures strike a balance between the distributed-memory and shared memory
              architectures by providing an abstraction of shared memory in software on
              distributed memories.  They are built using standard processors/workstations
              and they are easy to program using a shared address space based on virtual
              memory pages.  DSM systems are suitable for many parallel scientific
              applications.  Although many systems have been designed, only the scalability
              issues for hardware shared-memory systems have been addressed.    For software
              DSM systems, the focus has been on performance with a moderate number of nodes
              using relaxed memory consistency models and multiple-writers protocols.  Most
              experiments have been on 8 nodes and a few with 16 nodes.  When going from 8 to
              64 or more nodes, each  may have multiple processors, scalability problems
              exist with the current size of data structures and their allocation and
              deallocation.  A scalable DSM should only capture actual causality of
              modifications, minimize space overhead per shared page, and the address space
              should be dynamically partitioned.  We plan to analyze and build a scalable DSM
              system to run on a distributed-memory machine with 64 nodes and a fast
              interconnect.  ***
