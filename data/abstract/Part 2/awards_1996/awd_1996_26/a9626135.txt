Title       : Model Uncertainty in Prediction, Variable Selection and Related Decision
               Problems
Type        : Award
NSF Org     : DMS 
Latest
Amendment
Date        : June 18,  1996      
File        : a9626135

Award Number: 9626135
Award Instr.: Standard Grant                               
Prgm Manager: James L. Rosenberger                    
	      DMS  DIVISION OF MATHEMATICAL SCIENCES       
	      MPS  DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN
Start Date  : July 1,  1996       
Expires     : June 30,  2000       (Estimated)
Expected
Total Amt.  : $79000              (Estimated)
Investigator: Merlise A. Clyde clyde@stat.duke.edu  (Principal Investigator current)
Sponsor     : Duke University
	      327 North Building
	      Durham, NC  277080077    919/684-3030

NSF Program : 1269      STATISTICS
Fld Applictn: 0000099   Other Applications NEC                  
              21        Mathematics                             
Program Ref : 0000,OTHR,
Abstract    :
              DMS 9626135  Clyde     Statistical predictions based on complex models may be
              very sensitive to  modeling assumptions, such as choice of covariates.  As a
              result,  choosing a single model may not lead to satisfactory predictions and
              may  significantly underestimate prediction intervals due to not  incorporating
              uncertainty about the model choice into the final answer.  Model uncertainty
              often outweighs other sources of uncertainty in  problems, but is often
              ignored. Bayesian methods offer a very  effective and conceptually appealing
              alternative: predictions and  inferences can be based on a set of models rather
              than a single model;  each model contributes proportionally to the support it
              receives from  the observed data. This research involves Bayesian methods for 
              stochastically searching high dimensional model spaces.  As the number  of
              models is very large, the challenge is therefore that of finding  efficient
              ways of exploring the space of models, selecting plausible  ones, and
              attributing to each of them a weight (approximating the  posterior probability)
              for the mixing-based prediction or other utility  calculations.  Examples for
              the methodology include  applications in wavelets and generalized additive
              models: calibration  and prediction in spectroscopy using wavelet packets;
              determining the  influence of particulate matter on mortality adjusting for
              other  covariates in the presence of model uncertainty; and variable selection 
              and prediction in binary regression models for seedling survival.  Model 
              averaging using importance sampling to sample from high dimensional  model
              spaces is an effective solution.  This approach is extended to  selecting
              transformations of variables, subspace selection and  thresholding in wavelets,
              and generalized additive models in the  applications described above.  Methods
              for sampling models with a  probability proportional to their expected utility
              are also developed.  %%%  Finding and using models to describe data is a
              fundamental problem in  both statis tics and the sciences.  Statistical
              predictions may be very  sensitive to the set of explanatory variables included
              in a model.  Selecting a particular model based on selecting a subset of the 
              explanatory variables and using this model for prediction, may lead to  riskier
              decisions due to not incorporating uncertainty about model  choice into the
              final answer.  Model uncertainty often outweighs other  sources of uncertainty
              in problems, but is usually ignored.  In this  research, predictions and
              inferences can be based on a set of models  rather than a single model; each
              model contributes to the decision  proportionally to the support it receives
              from the observed data. As the  number of possible models is very large, the
              challenge is therefore that  of finding efficient ways of exploring the space
              of models, selecting  plausible ones, and attributing to each of them a weight
              for the  weighted prediction or other decisions. The methodological
              developments  are driven by the following applications: calibration and
              prediction in  spectroscopy; and determining the influence of particulate
              matter on  mortality adjusting for other meteorological variables when there is
               uncertainty about which variables should be included in the prediction  model.
               ***
