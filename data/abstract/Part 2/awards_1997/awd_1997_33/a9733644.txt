Title       : CAREER: Motion Planning and Active Vision Strategies for Optimizing Visual
               Feedback in Robot Control
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : July 31,  2002      
File        : a9733644

Award Number: 9733644
Award Instr.: Continuing grant                             
Prgm Manager: Junku Yuh                               
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : May 15,  1998       
Expires     : April 30,  2003      (Estimated)
Expected
Total Amt.  : $383934             (Estimated)
Investigator: Rajeev Sharma rsharma@cse.psu.edu  (Principal Investigator current)
Sponsor     : PA St U University Park
	      201 Old Main
	      University Park, PA  168021503    814/865-4700

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
Program Ref : 1045,1187,9216,HPCC,
Abstract    :
              This project investigates two complementary ways of improving  computer vision
              based robot control particularly in uncertain and  changing environments.
              First, by developing motion planning  techniques that account for properties of
              the visual data --  exploiting the available visual feedback and overcoming
              sensing  limitations.  This requires extending the notion of robot 
              configuration space to include image feature space and using 
              topology-preserving learning schemes to handle modeling  uncertainties. 
              Second, by developing active vision strategies  for optimizing visual feedback
              in robot control -- systematically  extending the range of robot operation
              beyond that possible by  static cameras. Defining invariances under camera
              motion would  allow the decoupling of active camera control from robot control.
               Both deterministic and stochastic strategies will be explored for  exploiting
              the camera motion in cooperation with the robot motion  plan. This research
              will be interleaved with supporting  educational activities which include
              developing new graduate  courses in robotics and human-computer interfaces,
              revising  undergraduate courses in related areas, and developing two new 
              educational tools. The first tool will be for collaborative group  projects on
              the web especially for projects involving video  images. The second tool will
              be for training and visualization  using an augmented reality interface that
              allows interactive  mixing of virtual and real objects.
