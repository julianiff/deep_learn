Title       : Interactive Handwritten Database Query Research
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : January 19,  2001   
File        : a9732914

Award Number: 9732914
Award Instr.: Standard Grant                               
Prgm Manager: Ephraim P. Glinert                      
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  1998     
Expires     : September 30,  2001  (Estimated)
Expected
Total Amt.  : $155534             (Estimated)
Investigator: Paul D. Gader gader@cecs.missouri.edu  (Principal Investigator current)
Sponsor     : U of Missouri Columbia
	      Office of Sponsored Prgm Admin
	      Columbia, MO  65211    573/882-7560

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
Program Ref : 9218,HPCC,
Abstract    :
              This  research  is  aimed  at supporting interaction  with  large  databases 
              that include handwritten documents.  The objective  is  to  advance 
              understanding  of  methodologies  for  interactively  querying  large  document
              databases.  Examples of such  documents  include  medical  and insurance
              information  systems  into  which  volumes  of paper records have been scanned,
              government  security  systems, and electronic historical document collections,
              such  as  the  collections  created by the Model Editions Partnership.   An 
              existing, high-performance handwritten recognition algorithm will  be  adapted 
              to  the  research  problem.   The  questions  to  be  addressed  include: 
              Which global, word-level training  objective  functions  result in better
              performance?  Which  character  class  confidence  measures result in better
              system  performance?   And,  which  character-based, word level confidence
              estimators  results  in   better  system  performance?  Experiments  will  
              focus   on  comparison of different methodologies for training; of  different 
              objective  functions,  optimization  criteria,  and  optimization 
              methodologies;  and of different methods of estimating  character  confidence.
